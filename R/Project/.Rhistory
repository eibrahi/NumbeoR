ggAcf(crimeGermanyTS)
meanf(crimeGermanyTS, h=3)
library(fpp2)
library(fpp)
detach("package:fpp", unload = TRUE)
library(fpp)
detach("package:fpp", unload = TRUE)
detach("package:fpp2", unload = TRUE)
library(fpp3)
meanf(crimeGermanyTS, h=3)
knit_with_parameters('C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/R/Project/NumbeoR.Rmd', encoding = 'UTF-8')
library(GGally)
GGally::ggpairs(select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`))
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp3)                          # forecasting/times series
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToJson <- paste0(path, "daten/dataImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToJson)
# creating lists
my_data <- list()
df_temp_my_data <- list()
df_my_data <- list()
for (i in 1 : length(my_files)) {
# creating a list of JSON datafiles importing from Github
my_data[[i]] <- fromJSON(file = my_files[i])
# transform JSON files to dataframes, for each JSON file one dataframe
df_temp_my_data[[i]] <- do.call(rbind.data.frame, my_data[[i]])
# transpos dataframes to get the required structure
df_my_data[[i]] <- as.data.frame(t(df_temp_my_data[[i]]))
# Writing data into PostgreSQL
if (i <= 8) {
dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 8 && i <= 16) {
dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 16 && i <= 24) {
dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 24 && i <= 32) {
dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else if (i > 32 && i <= 40) {
dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else {
dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}
}
View(my_data)
df_cost_of_living_postgres <- dbGetQuery(con, "SELECT * from cost_of_living")
df_crime_postgres <- dbGetQuery(con, "SELECT * from crime")
df_health_care_postgres <- dbGetQuery(con, "SELECT * from health_care")
df_pollution_postgres <- dbGetQuery(con, "SELECT * from pollution")
df_property_investment_postgres <- dbGetQuery(con, "SELECT * from property_investment")
df_traffic_postgres <- dbGetQuery(con, "SELECT * from traffic")
df_master <- full_join(full_join(full_join(full_join(full_join(df_cost_of_living_postgres, df_crime_postgres, by = c("Country", "Year")),df_health_care_postgres, by = c("Country", "Year")), df_pollution_postgres, by = c("Country", "Year")), df_property_investment_postgres, by = c("Country", "Year")), df_traffic_postgres, by = c("Country", "Year"))
df_master
df_master <- distinct(df_master)
df_master
filter(df_master, Country=="Germany")
glimpse(df_master)
countryContinent <- read.csv(file="https://raw.githubusercontent.com/eibrahi/NumbeoR/master/daten/CountryContinent.csv",header=TRUE, sep=";")
colnames(countryContinent) <- c("Country", "Continent")
glimpse(countryContinent)
countryContinent[] <- lapply(countryContinent, as.character)
glimpse(countryContinent)
df_master_continent <- left_join(df_master,countryContinent, by="Country")
sum(is.na(df_master_continent["Continent"]))
df_master_continent[rowSums(is.na(df_master_continent["Continent"])) > 0,]
glimpse(df_master_continent)
df_analysis <- select(df_master_continent, Year, Country, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index', Continent)
df_analysis
glimpse(df_analysis)
sum(is.na(df_analysis))
df_analysis[rowSums(is.na(df_analysis)) > 0,]
df_analysis_clean <- na.omit(df_analysis)
sum(is.na(df_analysis_clean))
glimpse(df_analysis_clean)
df_analysis_clean_2019 <- filter(df_analysis_clean, Year == 2019)
crime_plot_2019 <- ggplot(data=df_analysis_clean_2019, mapping=aes(x=Continent, y=`Crime Index`)) +
geom_boxplot()
ggplotly(crime_plot_2019)
crime_health_plot_2019 <- ggplot(df_analysis_clean_2019) +
geom_point(
mapping = aes(x = `Pollution Index`, y = `Cost of Living Index`,color= Continent, points=Country)
)
ggplotly(crime_health_plot_2019)
drops <- c("Year","Country", "Continent")
df_master_numeric <- df_master_continent[ , !(names(df_master_continent) %in% drops)]
df_master_numeric <- na.omit(df_master_numeric)
df_analysis_numeric <- select(df_master_numeric, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index')
sum(is.na(df_analysis_numeric))
# write.csv(df_master_continent,"C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/MasterDF.csv", row.names = FALSE)
corrplot(cor(df_analysis_numeric), method = "circle", title = "Correlation matrix")
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Local Purchasing Power Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Cost of Living Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield City Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield Outside of Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Health Care Index`,`Local Purchasing Power Index`)))
corN
df_Germany <- filter(df_master, Country=="Germany")
crimeGermanyVector <- df_Germany[,9]
crimeGermanyVector
costOfLivingVector <- df_Germany[,3]
costOfLivingVector
healthCareVector <- df_Germany[,11]
healthCareVector
pollutionVector <- df_Germany[,13]
pollutionVector
class(crimeGermanyVector)
crimeGermanyTS <- ts(crimeGermanyVector, start=2012, end=2019, frequency=1)
costOfLivingGermanyTS <- ts(costOfLivingVector, start=2012, end=2019, frequency=1)
healthCareGermanyTS <- ts(healthCareVector, start=2012, end=2019, frequency=1)
pollutionGermanyTS <- ts(pollutionVector, start=2012, end=2019, frequency=1)
crimeGermanyTS
class(crimeGermanyTS)
GermanyTS <- ts(df_Germany, start=2012, end=2019, frequency=1)
GermanyTS
par(mfrow=c(2,2))
plot(crimeGermanyTS, col="black", main="Crime Index Germany")
plot(costOfLivingGermanyTS, col="red", main="Cost of Living Index Germany")
plot(healthCareGermanyTS, col="orange", main="Health Care Index Germany")
plot(pollutionGermanyTS, col="purple", main="Pollution Index Germany")
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
meanf(crimeGermanyTS, h=3)
meanf(crimeGermanyTS, h=3)
meanf(crimeGermanyTS, h=3)
library(fpp2)
library(fpp)
meanf(crimeGermanyTS, h=3)
meanf(crimeGermanyTS, h=3)
naive(crimeGermanyTS, h=3)
driftCrime <- rwf(crimeGermanyTS, h=3, drift=TRUE)
driftCrime
crimeGermanyPlot <- window(crimeGermanyTS,start=2012,end=2019)
# Plot some forecasts
autoplot(crimeGermanyPlot) +
autolayer(meanf(crimeGermanyPlot, h=3),
series="Mean", PI=FALSE) +
autolayer(naive(crimeGermanyPlot, h=3),
series="Naïve", PI=FALSE) +
autolayer(rwf(crimeGermanyTS, h=3, drift=TRUE),
series="Naïve Drift Method", PI=FALSE) +
ggtitle("Forecasts for Crime Index") +
xlab("Year") + ylab("Crime Index") +
guides(colour=guide_legend(title="Forecast"))
crime1 <- meanf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime2 <- rwf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime3 <- rwf(window(crimeGermanyTS, start=2012, end=2016), drift=TRUE, h=3)
autoplot(crimeGermanyPlot) +
autolayer(crime1, PI=FALSE, series="Mean") +
autolayer(crime2, PI=FALSE, series="Naïve") +
autolayer(crime3, PI=FALSE, series="Naïve Drift Method") +
xlab("Year") + ylab("Crime Index") +
ggtitle("Crime Index Germany") +
guides(colour=guide_legend(title="Forecast"))
lag.plot(crimeGermanyTS,lags=7,do.lines=FALSE)
ggAcf(crimeGermanyTS)
install.packages(c("fpp", "fpp2", "fpp3", "GGally", "Hmisc"))
install.packages("xaringan")
options(htmltools.dir.version = FALSE)
devtools::install_github("yihui/xaringan")
knitr::opts_chunk$set(echo = TRUE)
# load configfile
configFile <- fromJSON(file="configFile.json")
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToJson <- paste0(path, "daten/dataImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToJson)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToJson <- paste0(path, "daten/dataImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToJson)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToJson <- paste0(path, "daten/dataImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToJson)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToJson <- paste0(path, "daten/dataImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToJson)
# creating lists
my_data <- list()
df_temp_my_data <- list()
df_my_data <- list()
for (i in 1 : length(my_files)) {
# creating a list of JSON datafiles importing from Github
my_data[[i]] <- fromJSON(file = my_files[i])
# transform JSON files to dataframes, for each JSON file one dataframe
df_temp_my_data[[i]] <- do.call(rbind.data.frame, my_data[[i]])
# transpose dataframes to get the required structure
df_my_data[[i]] <- as.data.frame(t(df_temp_my_data[[i]]))
# Writing data into PostgreSQL
if (i <= 8) {
dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 8 && i <= 16) {
dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 16 && i <= 24) {
dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 24 && i <= 32) {
dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else if (i > 32 && i <= 40) {
dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else {
dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}
}
df_cost_of_living_postgres <- dbGetQuery(con, "SELECT * from cost_of_living")
df_crime_postgres <- dbGetQuery(con, "SELECT * from crime")
df_health_care_postgres <- dbGetQuery(con, "SELECT * from health_care")
df_pollution_postgres <- dbGetQuery(con, "SELECT * from pollution")
df_property_investment_postgres <- dbGetQuery(con, "SELECT * from property_investment")
df_traffic_postgres <- dbGetQuery(con, "SELECT * from traffic")
df_master <- full_join(full_join(full_join(full_join(full_join(df_cost_of_living_postgres, df_crime_postgres, by = c("Country", "Year")),df_health_care_postgres, by = c("Country", "Year")), df_pollution_postgres, by = c("Country", "Year")), df_property_investment_postgres, by = c("Country", "Year")), df_traffic_postgres, by = c("Country", "Year"))
df_master
df_master <- distinct(df_master)
df_master
filter(df_master, Country=="Germany")
glimpse(df_master)
countryContinent <- read.csv(file="https://raw.githubusercontent.com/eibrahi/NumbeoR/master/daten/CountryContinent.csv",header=TRUE, sep=";")
colnames(countryContinent) <- c("Country", "Continent")
glimpse(countryContinent)
countryContinent[] <- lapply(countryContinent, as.character)
glimpse(countryContinent)
df_master_continent <- left_join(df_master,countryContinent, by="Country")
sum(is.na(df_master_continent["Continent"]))
df_master_continent[rowSums(is.na(df_master_continent["Continent"])) > 0,]
glimpse(df_master_continent)
df_analysis <- select(df_master_continent, Year, Country, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index', Continent)
df_analysis
glimpse(df_analysis)
sum(is.na(df_analysis))
df_analysis[rowSums(is.na(df_analysis)) > 0,]
df_analysis_clean <- na.omit(df_analysis)
sum(is.na(df_analysis_clean))
glimpse(df_analysis_clean)
df_analysis_clean_2019 <- filter(df_analysis_clean, Year == 2019)
crime_plot_2019 <- ggplot(data=df_analysis_clean_2019, mapping=aes(x=Continent, y=`Crime Index`)) +
geom_boxplot()
ggplotly(crime_plot_2019)
crime_health_plot_2019 <- ggplot(df_analysis_clean_2019) +
geom_point(
mapping = aes(x = `Pollution Index`, y = `Cost of Living Index`,color= Continent, points=Country)
)
ggplotly(crime_health_plot_2019)
drops <- c("Year","Country", "Continent")
df_master_numeric <- df_master_continent[ , !(names(df_master_continent) %in% drops)]
df_master_numeric <- na.omit(df_master_numeric)
df_analysis_numeric <- select(df_master_numeric, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index')
sum(is.na(df_analysis_numeric))
# write.csv(df_master_continent,"C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/MasterDF.csv", row.names = FALSE)
corrplot(cor(df_analysis_numeric), method = "circle", title = "Correlation matrix")
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Local Purchasing Power Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Cost of Living Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield City Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield Outside of Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Health Care Index`,`Local Purchasing Power Index`)))
corN
df_Germany <- filter(df_master, Country=="Germany")
crimeGermanyVector <- df_Germany[,9]
crimeGermanyVector
costOfLivingVector <- df_Germany[,3]
costOfLivingVector
healthCareVector <- df_Germany[,11]
healthCareVector
pollutionVector <- df_Germany[,13]
pollutionVector
class(crimeGermanyVector)
crimeGermanyTS <- ts(crimeGermanyVector, start=2012, end=2019, frequency=1)
costOfLivingGermanyTS <- ts(costOfLivingVector, start=2012, end=2019, frequency=1)
healthCareGermanyTS <- ts(healthCareVector, start=2012, end=2019, frequency=1)
pollutionGermanyTS <- ts(pollutionVector, start=2012, end=2019, frequency=1)
crimeGermanyTS
class(crimeGermanyTS)
GermanyTS <- ts(df_Germany, start=2012, end=2019, frequency=1)
GermanyTS
par(mfrow=c(2,2))
plot(crimeGermanyTS, col="black", main="Crime Index Germany")
plot(costOfLivingGermanyTS, col="red", main="Cost of Living Index Germany")
plot(healthCareGermanyTS, col="orange", main="Health Care Index Germany")
plot(pollutionGermanyTS, col="purple", main="Pollution Index Germany")
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
meanf(crimeGermanyTS, h=3)
naive(crimeGermanyTS, h=3)
driftCrime <- rwf(crimeGermanyTS, h=3, drift=TRUE)
driftCrime
crimeGermanyPlot <- window(crimeGermanyTS,start=2012,end=2019)
# Plot some forecasts
autoplot(crimeGermanyPlot) +
autolayer(meanf(crimeGermanyPlot, h=3),
series="Mean", PI=FALSE) +
autolayer(naive(crimeGermanyPlot, h=3),
series="Naïve", PI=FALSE) +
autolayer(rwf(crimeGermanyTS, h=3, drift=TRUE),
series="Naïve Drift Method", PI=FALSE) +
ggtitle("Forecasts for Crime Index") +
xlab("Year") + ylab("Crime Index") +
guides(colour=guide_legend(title="Forecast"))
crime1 <- meanf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime2 <- rwf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime3 <- rwf(window(crimeGermanyTS, start=2012, end=2016), drift=TRUE, h=3)
autoplot(crimeGermanyPlot) +
autolayer(crime1, PI=FALSE, series="Mean") +
autolayer(crime2, PI=FALSE, series="Naïve") +
autolayer(crime3, PI=FALSE, series="Naïve Drift Method") +
xlab("Year") + ylab("Crime Index") +
ggtitle("Crime Index Germany") +
guides(colour=guide_legend(title="Forecast"))
lag.plot(crimeGermanyTS,lags=7,do.lines=FALSE)
ggAcf(crimeGermanyTS)
