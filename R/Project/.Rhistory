# Writing data into PostgreSQL
if (i <= 8) {
dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 8 && i <= 16) {
dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 16 && i <= 24) {
dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 24 && i <= 32) {
dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else if (i > 32 && i <= 40) {
dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else {
dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}
}
# generate full path to the dataImport.json
pathToDataJson <- paste0(path, "daten/dataImport.json")
pathToTableJson <- paste0(path, "daten/tableNamesImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToDataJson)
my_tables <- fromJSON(file= pathToTableJson)
# creating lists
my_data <- list()
df_temp_my_data <- list()
df_my_data <- list()
for (i in 1 : length(my_files)) {
# creating a list of JSON datafiles importing from Github
my_data[[i]] <- fromJSON(file = my_files[i])
# transform JSON files to dataframes, for each JSON file one dataframe
df_temp_my_data[[i]] <- do.call(rbind.data.frame, my_data[[i]])
# transpose dataframes to get the required structure
df_my_data[[i]] <- as.data.frame(t(df_temp_my_data[[i]]))
# Writing data into PostgreSQL
if (i <= 8) {
dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 8 && i <= 16) {
dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 16 && i <= 24) {
dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 24 && i <= 32) {
dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else if (i > 32 && i <= 40) {
dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else {
dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
library(tsibble)                       # tsibble object used for forecasting
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToDataJson <- paste0(path, "daten/dataImport.json")
pathToTableJson <- paste0(path, "daten/tableNamesImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToDataJson)
my_tables <- fromJSON(file= pathToTableJson)
# creating lists
my_data <- list()
df_temp_my_data <- list()
df_my_data <- list()
for (i in 1 : length(my_files)) {
# creating a list of JSON datafiles importing from Github
my_data[[i]] <- fromJSON(file = my_files[i])
# transform JSON files to dataframes, for each JSON file one dataframe
df_temp_my_data[[i]] <- do.call(rbind.data.frame, my_data[[i]])
# transpose dataframes to get the required structure
df_my_data[[i]] <- as.data.frame(t(df_temp_my_data[[i]]))
# Writing data into PostgreSQL
if (i <= 8) {
dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 8 && i <= 16) {
dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 16 && i <= 24) {
dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
} else if (i > 24 && i <= 32) {
dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else if (i > 32 && i <= 40) {
dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}else {
dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
}
}
df_cost_of_living_postgres <- dbGetQuery(con, "SELECT * from cost_of_living")
df_crime_postgres <- dbGetQuery(con, "SELECT * from crime")
df_health_care_postgres <- dbGetQuery(con, "SELECT * from health_care")
df_pollution_postgres <- dbGetQuery(con, "SELECT * from pollution")
df_property_investment_postgres <- dbGetQuery(con, "SELECT * from property_investment")
df_traffic_postgres <- dbGetQuery(con, "SELECT * from traffic")
df_master <- full_join(full_join(full_join(full_join(full_join(df_cost_of_living_postgres, df_crime_postgres, by = c("Country", "Year")),df_health_care_postgres, by = c("Country", "Year")), df_pollution_postgres, by = c("Country", "Year")), df_property_investment_postgres, by = c("Country", "Year")), df_traffic_postgres, by = c("Country", "Year"))
df_master
df_master <- distinct(df_master)
df_master
filter(df_master, Country=="Germany")
glimpse(df_master)
countryContinent <- read.csv(file="https://raw.githubusercontent.com/eibrahi/NumbeoR/master/daten/CountryContinent.csv",header=TRUE, sep=";")
colnames(countryContinent) <- c("Country", "Continent")
glimpse(countryContinent)
countryContinent[] <- lapply(countryContinent, as.character)
glimpse(countryContinent)
df_master_continent <- left_join(df_master,countryContinent, by="Country")
sum(is.na(df_master_continent["Continent"]))
df_master_continent[rowSums(is.na(df_master_continent["Continent"])) > 0,]
glimpse(df_master_continent)
df_analysis <- select(df_master_continent, Year, Country, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index', Continent)
df_analysis
glimpse(df_analysis)
sum(is.na(df_analysis))
df_analysis[rowSums(is.na(df_analysis)) > 0,]
df_analysis_clean <- na.omit(df_analysis)
sum(is.na(df_analysis_clean))
glimpse(df_analysis_clean)
df_analysis_clean_2019 <- filter(df_analysis_clean, Year == 2019)
drops <- c("Year","Country", "Continent")
df_master_numeric <- df_master_continent[ , !(names(df_master_continent) %in% drops)]
df_master_numeric <- na.omit(df_master_numeric)
df_analysis_numeric <- select(df_master_numeric, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index')
sum(is.na(df_analysis_numeric))
corrplot(cor(df_analysis_numeric), method = "circle")
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Local Purchasing Power Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Cost of Living Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield City Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield Outside of Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Health Care Index`,`Local Purchasing Power Index`)))
corN
crime_plot_2019 <- ggplot(data=df_analysis_clean_2019, mapping=aes(x=Continent, y=`Crime Index`)) +
geom_boxplot()
ggplotly(crime_plot_2019)
crime_health_plot_2019 <- ggplot(df_analysis_clean_2019) +
geom_point(
mapping = aes(x = `Pollution Index`, y = `Cost of Living Index`,color= Continent, points=Country)
)
ggplotly(crime_health_plot_2019)
df_Germany <- filter(df_master, Country=="Germany")
tsibble_Germany <- as_tsibble(df_Germany, index=Year)
class(tsibble_Germany)
tsibble_Germany
crimeGermanyVector <- df_Germany[,9]
crimeGermanyVector
costOfLivingVector <- df_Germany[,3]
costOfLivingVector
healthCareVector <- df_Germany[,11]
healthCareVector
pollutionVector <- df_Germany[,13]
pollutionVector
class(crimeGermanyVector)
crimeGermanyTS <- ts(crimeGermanyVector, start=2012, end=2019, frequency=1)
costOfLivingGermanyTS <- ts(costOfLivingVector, start=2012, end=2019, frequency=1)
healthCareGermanyTS <- ts(healthCareVector, start=2012, end=2019, frequency=1)
pollutionGermanyTS <- ts(pollutionVector, start=2012, end=2019, frequency=1)
crimeGermanyTS
class(crimeGermanyTS)
GermanyTS <- ts(df_Germany, start=2012, end=2019, frequency=1)
GermanyTS
autoplot(tsibble_Germany,`Crime Index`, col="black") +
labs(title = "Crime Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
autoplot(tsibble_Germany,`Cost of Living Index`, col="red") +
labs(title = "Cost of Living Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
autoplot(tsibble_Germany,`Health Care Index`, col="orange") +
labs(title = "Health Care Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
autoplot(tsibble_Germany,`Pollution Index`, col="purple") +
labs(title = "Pollution Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
par(mfrow=c(2,2))
plot(crimeGermanyTS, col="black", main="Crime Index Germany")
plot(costOfLivingGermanyTS, col="red", main="Cost of Living Index Germany")
plot(healthCareGermanyTS, col="orange", main="Health Care Index Germany")
plot(pollutionGermanyTS, col="purple", main="Pollution Index Germany")
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
meanf(crimeGermanyTS, h=3)
naive(crimeGermanyTS, h=3)
driftCrime <- rwf(crimeGermanyTS, h=3, drift=TRUE)
driftCrime
crimeGermanyPlot <- window(crimeGermanyTS,start=2012,end=2019)
# Plot some forecasts
autoplot(crimeGermanyPlot) +
autolayer(meanf(crimeGermanyPlot, h=3),
series="Mean", PI=FALSE) +
autolayer(naive(crimeGermanyPlot, h=3),
series="Naïve", PI=FALSE) +
autolayer(rwf(crimeGermanyTS, h=3, drift=TRUE),
series="Naïve Drift Method", PI=FALSE) +
ggtitle("Forecasts for Crime Index") +
xlab("Year") + ylab("Crime Index") +
guides(colour=guide_legend(title="Forecast"))
crime1 <- meanf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime2 <- rwf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime3 <- rwf(window(crimeGermanyTS, start=2012, end=2016), drift=TRUE, h=3)
autoplot(crimeGermanyPlot) +
autolayer(crime1, PI=FALSE, series="Mean") +
autolayer(crime2, PI=FALSE, series="Naïve") +
autolayer(crime3, PI=FALSE, series="Naïve Drift Method") +
xlab("Year") + ylab("Crime Index") +
ggtitle("Forecast for Crime Index Germany") +
guides(colour=guide_legend(title="Forecast"))
# Set training data from 2012 to 2016
train <- select(tsibble_Germany,`Crime Index`) %>% filter_index("2012" ~ "2016")
# Fit the models
crime_fit <- train %>%
model(
`Mean` = MEAN(`Crime Index`),
`Naïve` = NAIVE(`Crime Index`),
`Drift` = NAIVE(`Crime Index` ~ drift())
)
# Generate forecasts for 3 years
crime_fc <- crime_fit %>% forecast(h=3)
# Plot forecasts against actual values
crime_fc %>%
autoplot(train, level = NULL) +
autolayer(filter_index(select(tsibble_Germany,`Crime Index`), "2016" ~ "2019"), color = "black") +
ggtitle("Forecast for Crime Index Germany") +
xlab("Year") + ylab("Crime Index") +
guides(colour=guide_legend(title="Forecast"))
#lag.plot(crimeGermanyTS,lags=7,do.lines=FALSE) # Variante 1
tsibble_Germany %>%  gg_lag(`Crime Index`, geom="point")  # Variante 2
# ggAcf(crimeGermanyTS) # Variante 1
autoplot(ACF(tsibble_Germany, `Crime Index`)) # Variante 2
fit <- tsibble_Germany %>%  model(trend_model = TSLM(`Crime Index` ~ trend()))
fit
fit %>% forecast(h = "3 years") %>%
autoplot(tsibble_Germany) +
ggtitle("Crime Index for Germany") + ylab("Crime Index")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL
library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files
library(plotly)                        # visualizations
library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations
library(Hmisc)                         # calculation of correlations
library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series
library(tsibble)                       # tsibble object used for forecasting
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
pw = configFile[2]
# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL")
# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
host = "localhost", port = 5432,
user = "postgres", password = pw)
# removes the password
rm(pw)
# generate full path to the dataImport.json
pathToDataJson <- paste0(path, "daten/dataImport.json")
pathToTableJson <- paste0(path, "daten/tableNamesImport.json")
# reeding the dataImport.json
my_files <- fromJSON(file = pathToDataJson)
my_tables <- fromJSON(file= pathToTableJson)
# creating lists
my_data <- list()
df_temp_my_data <- list()
df_my_data <- list()
for (i in 1 : length(my_files)) {
# creating a list of JSON datafiles importing from Github
my_data[[i]] <- fromJSON(file = my_files[i])
# transform JSON files to dataframes, for each JSON file one dataframe
df_temp_my_data[[i]] <- do.call(rbind.data.frame, my_data[[i]])
# transpose dataframes to get the required structure
df_my_data[[i]] <- as.data.frame(t(df_temp_my_data[[i]]))
# Writing data into PostgreSQL
dbWriteTable(con, my_tables[i], value = df_my_data[[i]], append = TRUE, row.names = FALSE)
#  if (i <= 8) {
#     dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
# } else if (i > 8 && i <= 16) {
#     dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
# } else if (i > 16 && i <= 24) {
#     dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
# } else if (i > 24 && i <= 32) {
#     dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
# }else if (i > 32 && i <= 40) {
#     dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
# }else {
#     dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
# }
}
df_cost_of_living_postgres <- dbGetQuery(con, "SELECT * from cost_of_living")
df_crime_postgres <- dbGetQuery(con, "SELECT * from crime")
df_health_care_postgres <- dbGetQuery(con, "SELECT * from health_care")
df_pollution_postgres <- dbGetQuery(con, "SELECT * from pollution")
df_property_investment_postgres <- dbGetQuery(con, "SELECT * from property_investment")
df_traffic_postgres <- dbGetQuery(con, "SELECT * from traffic")
df_master <- full_join(full_join(full_join(full_join(full_join(df_cost_of_living_postgres, df_crime_postgres, by = c("Country", "Year")),df_health_care_postgres, by = c("Country", "Year")), df_pollution_postgres, by = c("Country", "Year")), df_property_investment_postgres, by = c("Country", "Year")), df_traffic_postgres, by = c("Country", "Year"))
df_master
df_master <- distinct(df_master)
df_master
filter(df_master, Country=="Germany")
glimpse(df_master)
countryContinent <- read.csv(file="https://raw.githubusercontent.com/eibrahi/NumbeoR/master/daten/CountryContinent.csv",header=TRUE, sep=";")
colnames(countryContinent) <- c("Country", "Continent")
glimpse(countryContinent)
countryContinent[] <- lapply(countryContinent, as.character)
glimpse(countryContinent)
df_master_continent <- left_join(df_master,countryContinent, by="Country")
sum(is.na(df_master_continent["Continent"]))
df_master_continent[rowSums(is.na(df_master_continent["Continent"])) > 0,]
glimpse(df_master_continent)
df_analysis <- select(df_master_continent, Year, Country, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index', Continent)
df_analysis
glimpse(df_analysis)
sum(is.na(df_analysis))
df_analysis[rowSums(is.na(df_analysis)) > 0,]
df_analysis_clean <- na.omit(df_analysis)
sum(is.na(df_analysis_clean))
glimpse(df_analysis_clean)
df_analysis_clean_2019 <- filter(df_analysis_clean, Year == 2019)
drops <- c("Year","Country", "Continent")
df_master_numeric <- df_master_continent[ , !(names(df_master_continent) %in% drops)]
df_master_numeric <- na.omit(df_master_numeric)
df_analysis_numeric <- select(df_master_numeric, 'Cost of Living Index', 'Rent Index',
'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
'Gross Rental Yield Outside of Centre',
'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
'CO2 Emission Index')
sum(is.na(df_analysis_numeric))
corrplot(cor(df_analysis_numeric), method = "circle")
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Local Purchasing Power Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Cost of Living Index`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield City Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield Outside of Centre`)))
corN
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Health Care Index`,`Local Purchasing Power Index`)))
corN
crime_plot_2019 <- ggplot(data=df_analysis_clean_2019, mapping=aes(x=Continent, y=`Crime Index`)) +
geom_boxplot()
ggplotly(crime_plot_2019)
crime_health_plot_2019 <- ggplot(df_analysis_clean_2019) +
geom_point(
mapping = aes(x = `Pollution Index`, y = `Cost of Living Index`,color= Continent, points=Country)
)
ggplotly(crime_health_plot_2019)
df_Germany <- filter(df_master, Country=="Germany")
tsibble_Germany <- as_tsibble(df_Germany, index=Year)
class(tsibble_Germany)
tsibble_Germany
crimeGermanyVector <- df_Germany[,9]
crimeGermanyVector
costOfLivingVector <- df_Germany[,3]
costOfLivingVector
healthCareVector <- df_Germany[,11]
healthCareVector
pollutionVector <- df_Germany[,13]
pollutionVector
class(crimeGermanyVector)
crimeGermanyTS <- ts(crimeGermanyVector, start=2012, end=2019, frequency=1)
costOfLivingGermanyTS <- ts(costOfLivingVector, start=2012, end=2019, frequency=1)
healthCareGermanyTS <- ts(healthCareVector, start=2012, end=2019, frequency=1)
pollutionGermanyTS <- ts(pollutionVector, start=2012, end=2019, frequency=1)
crimeGermanyTS
class(crimeGermanyTS)
GermanyTS <- ts(df_Germany, start=2012, end=2019, frequency=1)
GermanyTS
autoplot(tsibble_Germany,`Crime Index`, col="black") +
labs(title = "Crime Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
autoplot(tsibble_Germany,`Cost of Living Index`, col="red") +
labs(title = "Cost of Living Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
autoplot(tsibble_Germany,`Health Care Index`, col="orange") +
labs(title = "Health Care Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
autoplot(tsibble_Germany,`Pollution Index`, col="purple") +
labs(title = "Pollution Index Germany", subtitle = "Years 2012-2019") +
xlab("Year")
par(mfrow=c(2,2))
plot(crimeGermanyTS, col="black", main="Crime Index Germany")
plot(costOfLivingGermanyTS, col="red", main="Cost of Living Index Germany")
plot(healthCareGermanyTS, col="orange", main="Health Care Index Germany")
plot(pollutionGermanyTS, col="purple", main="Pollution Index Germany")
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
meanf(crimeGermanyTS, h=3)
naive(crimeGermanyTS, h=3)
driftCrime <- rwf(crimeGermanyTS, h=3, drift=TRUE)
driftCrime
crimeGermanyPlot <- window(crimeGermanyTS,start=2012,end=2019)
# Plot some forecasts
autoplot(crimeGermanyPlot) +
autolayer(meanf(crimeGermanyPlot, h=3),
series="Mean", PI=FALSE) +
autolayer(naive(crimeGermanyPlot, h=3),
series="Naïve", PI=FALSE) +
autolayer(rwf(crimeGermanyTS, h=3, drift=TRUE),
series="Naïve Drift Method", PI=FALSE) +
ggtitle("Forecasts for Crime Index") +
xlab("Year") + ylab("Crime Index") +
guides(colour=guide_legend(title="Forecast"))
crime1 <- meanf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime2 <- rwf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime3 <- rwf(window(crimeGermanyTS, start=2012, end=2016), drift=TRUE, h=3)
autoplot(crimeGermanyPlot) +
autolayer(crime1, PI=FALSE, series="Mean") +
autolayer(crime2, PI=FALSE, series="Naïve") +
autolayer(crime3, PI=FALSE, series="Naïve Drift Method") +
xlab("Year") + ylab("Crime Index") +
ggtitle("Forecast for Crime Index Germany") +
guides(colour=guide_legend(title="Forecast"))
# Set training data from 2012 to 2016
train <- select(tsibble_Germany,`Crime Index`) %>% filter_index("2012" ~ "2016")
# Fit the models
crime_fit <- train %>%
model(
`Mean` = MEAN(`Crime Index`),
`Naïve` = NAIVE(`Crime Index`),
`Drift` = NAIVE(`Crime Index` ~ drift())
)
# Generate forecasts for 3 years
crime_fc <- crime_fit %>% forecast(h=3)
# Plot forecasts against actual values
crime_fc %>%
autoplot(train, level = NULL) +
autolayer(filter_index(select(tsibble_Germany,`Crime Index`), "2016" ~ "2019"), color = "black") +
ggtitle("Forecast for Crime Index Germany") +
xlab("Year") + ylab("Crime Index") +
guides(colour=guide_legend(title="Forecast"))
#lag.plot(crimeGermanyTS,lags=7,do.lines=FALSE) # Variante 1
tsibble_Germany %>%  gg_lag(`Crime Index`, geom="point")  # Variante 2
# ggAcf(crimeGermanyTS) # Variante 1
autoplot(ACF(tsibble_Germany, `Crime Index`)) # Variante 2
fit <- tsibble_Germany %>%  model(trend_model = TSLM(`Crime Index` ~ trend()))
fit
fit %>% forecast(h = "3 years") %>%
autoplot(tsibble_Germany) +
ggtitle("Crime Index for Germany") + ylab("Crime Index")
shiny::runApp('C:/Users/elvir/Desktop/rubbish/Testovic')
library(shiny)
# Call this function with all the regular navbarPage() parameters, plus a text parameter,
# if you want to add text to the navbar
navbarPageWithText <- function(..., text) {
navbar <- navbarPage(...)
textEl <- tags$p(class = "navbar-text", text)
navbar[[3]][[1]]$children[[1]] <- htmltools::tagAppendChild(
navbar[[3]][[1]]$children[[1]], textEl)
navbar
}
# Call this function with an input (such as `textInput("text", NULL, "Search")`) if you
# want to add an input to the navbar
navbarPageWithInputs <- function(..., inputs) {
navbar <- navbarPage(...)
form <- tags$form(class = "navbar-form", inputs)
navbar[[3]][[1]]$children[[1]] <- htmltools::tagAppendChild(
navbar[[3]][[1]]$children[[1]], form)
navbar
}
# When creating the UI, call our wrapper function instead of `navbarPage()`
ui <- navbarPageWithText(
"Test app",
tabPanel("tab1", "tab 1"),
tabPanel("tab2", "tab 2"),
text = "User: Dean"
)
server <- function(input, output, session) {
}
shinyApp(ui = ui, server = server)
runApp('NumbeoS')
View(crime_health_plot_2019)
