---
title: "Project assignment NumbeoR"
author: "Elvir Ibrahimovic & Svetislav Bratic"
date: "29 9 2019"
output: 
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


---
class: center, middle

# Project Description

---

# Loading of required libraries

```{r, message=FALSE}
library(tidyverse)

library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL

library(jsonlite)                      # handling of JSON files
library(rjson)                         # handling of JSON files

library(plotly)                        # visualizations

library(corrplot)                      # visualizations of correlations
library(GGally)                        # visualizations of correlations

library(Hmisc)                         # calculation of correlations

library(fpp)                           # forecasting/times series
library(fpp2)                          # forecasting/times series
library(fpp3)                          # forecasting/times series


```

---
class: center, middle

# Setup of the PostgreSQL database

---

## Establishing connection to PostgreSQL


```{r echo=TRUE}
# load configfile
configFile <- fromJSON(file="configFile.json")
path <- configFile[1]
```


```{r echo=TRUE}
pw = configFile[2]

# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL") 

# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
                 host = "localhost", port = 5432,
                 user = "postgres", password = pw)

# removes the password
rm(pw)

```


---

## Creation of database
A database with the name "NumbeoR" in PostgreSQL has to be created manually. 

---

## Creation of tables

```{sql connection=con}
DROP Table cost_of_living, crime, health_care, pollution, property_investment, traffic
```


Six different tables need to be created:

```{sql echo=TRUE, connection=con}
CREATE TABLE cost_of_living (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Cost of Living Index" numeric,                   -- Cost of Living Index
    "Rent Index" numeric,                             -- Rent Index
    "Cost of Living Plus Rent Index" numeric,   
    "Groceries Index" numeric,                   
    "Restaurant Price Index" numeric,                  
    "Local Purchasing Power Index" numeric                        
);

CREATE TABLE crime (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Crime Index" numeric,              
    "Safety Index" numeric
);

CREATE TABLE health_care (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Health Care Index" numeric,              
    "Health CareExp. Index" numeric                        
);

CREATE TABLE pollution (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Pollution Index" numeric,              
    "Exp Pollution Index" numeric                       
);

CREATE TABLE property_investment (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Price To Income Ratio" numeric,              
    "Gross Rental Yield City Centre" numeric,                        
    "Gross Rental Yield Outside of Centre" numeric,   
    "Price To Rent Ratio City Centre" numeric,                   
    "Price To Rent Ratio Outside Of City Centre" numeric,                  
    "Mortgage As A Percentage Of Income" numeric,                   
    "Affordability Index" numeric                      
);

CREATE TABLE traffic (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Traffic Index" numeric,              
    "Time Index(in minutes)" numeric,                        
    "Time Exp. Index" numeric,   
    "Inefficiency Index" numeric,                   
    "CO2 Emission Index" numeric                        
);


```

---


# Data import

---

Reading in the JSON files

```{r echo=TRUE}
# generate full path to the dataImport.json
pathToJson <- paste0(path, "daten/dataImport.json")

# reeding the dataImport.json
my_files <- fromJSON(file = pathToJson)

# creating lists
my_data <- list()
df_temp_my_data <- list()
df_my_data <- list()

for (i in 1 : length(my_files)) {
    # creating a list of JSON datafiles importing from Github
    my_data[[i]] <- fromJSON(file = my_files[i])
   
     # transform JSON files to dataframes, for each JSON file one dataframe
    df_temp_my_data[[i]] <- do.call(rbind.data.frame, my_data[[i]])
    
    # transpose dataframes to get the required structure
    df_my_data[[i]] <- as.data.frame(t(df_temp_my_data[[i]]))  
    
    # Writing data into PostgreSQL
    if (i <= 8) {
        dbWriteTable(con, "cost_of_living", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
    } else if (i > 8 && i <= 16) {
        dbWriteTable(con, "crime", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
    } else if (i > 16 && i <= 24) {
        dbWriteTable(con, "health_care", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
    } else if (i > 24 && i <= 32) {
        dbWriteTable(con, "pollution", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
    }else if (i > 32 && i <= 40) {
        dbWriteTable(con, "property_investment", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
    }else {
        dbWriteTable(con, "traffic", value = df_my_data[[i]], append = TRUE, row.names = FALSE)
    }
}
```


---

# Export Data From PostgreSQL

---

There are different ways for exporting and further preparing data from PostgreSQL
One could export with sQL codes
We use R codes instead

---

## R code

---

Export of the different tables with the help of dbGetQuery function

```{r}
df_cost_of_living_postgres <- dbGetQuery(con, "SELECT * from cost_of_living")
df_crime_postgres <- dbGetQuery(con, "SELECT * from crime")
df_health_care_postgres <- dbGetQuery(con, "SELECT * from health_care")
df_pollution_postgres <- dbGetQuery(con, "SELECT * from pollution")
df_property_investment_postgres <- dbGetQuery(con, "SELECT * from property_investment")
df_traffic_postgres <- dbGetQuery(con, "SELECT * from traffic")
```

---
Joining the data to one master dataframe

```{r}
df_master <- full_join(full_join(full_join(full_join(full_join(df_cost_of_living_postgres, df_crime_postgres, by = c("Country", "Year")),df_health_care_postgres, by = c("Country", "Year")), df_pollution_postgres, by = c("Country", "Year")), df_property_investment_postgres, by = c("Country", "Year")), df_traffic_postgres, by = c("Country", "Year"))


df_master
```

```{r}
df_master <- distinct(df_master)

```

```{r}
df_master
```

---

Filtering the master dataframe for country 'Germany'

```{r}
filter(df_master, Country=="Germany")
```

---

## SQL code

---

# Data Understanding and Preparation

---

## Approach:

* Detailed inspection of data and data structure
* Selection of content to be used afterwards
* Outlier detection with the help of descriptive statistics
* Data cleansing (e.g. outlier, NaNs)
* Final validation and verification of data set

---

## Data inspection

---

A summary of dataframe structure and data types can be illustrated with the glimpse function:
```{r}
glimpse(df_master)
```

---

Furthermore we would like to add the information in which continent the country is.

Therefore we import a table which includes a country continent mapping

```{r}
countryContinent <- read.csv(file="https://raw.githubusercontent.com/eibrahi/NumbeoR/master/daten/CountryContinent.csv",header=TRUE, sep=";")
colnames(countryContinent) <- c("Country", "Continent")
```

---

Checking the data types we see that the data was defined as factors

```{r}
glimpse(countryContinent)
```

Therefore we change the data types to characters 
```{r}
countryContinent[] <- lapply(countryContinent, as.character)
```

```{r}
glimpse(countryContinent)
```

---

Now we can join the continents to the master dataframe with the help of a left_join function:

```{r}
df_master_continent <- left_join(df_master,countryContinent, by="Country")
```

Checking the number of NA values within the column 'Continent' shows that there are no ones
```{r}
sum(is.na(df_master_continent["Continent"]))

```

```{r}
df_master_continent[rowSums(is.na(df_master_continent["Continent"])) > 0,]
```

For every country one contintent could be assigened.

```{r}
glimpse(df_master_continent)
```

---

## Data selection

---

Selection of variables which are to be used in later analyses

```{r}
df_analysis <- select(df_master_continent, Year, Country, 'Cost of Living Index', 'Rent Index',
    'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
    'Gross Rental Yield Outside of Centre',
    'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
    'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
    'CO2 Emission Index', Continent)


```



```{r}
df_analysis

```

```{r}
glimpse(df_analysis)
```

---

## Data Cleansing

---
### Deletion of NA values

Sum of NA values can be ascertained as following:
```{r}
sum(is.na(df_analysis))
```

The observations which contain at least one NA values can be identified with the following command:

```{r}
df_analysis[rowSums(is.na(df_analysis)) > 0,]
```

---

All rows containing NA values can be deleted with the na.omit function:

```{r}
df_analysis_clean <- na.omit(df_analysis)

```

Checking on how many NA values are in the new clean dataframe shows that there are none

```{r}
sum(is.na(df_analysis_clean))
```

The new structure of the dataframe is
```{r}
glimpse(df_analysis_clean)
```


---

```{r}
df_analysis_clean_2019 <- filter(df_analysis_clean, Year == 2019)
```


```{r}
crime_plot_2019 <- ggplot(data=df_analysis_clean_2019, mapping=aes(x=Continent, y=`Crime Index`)) +
                         geom_boxplot()
                     
ggplotly(crime_plot_2019)
```



---


```{r}
crime_health_plot_2019 <- ggplot(df_analysis_clean_2019) +
    geom_point(
        mapping = aes(x = `Pollution Index`, y = `Cost of Living Index`,color= Continent, points=Country)
        )

ggplotly(crime_health_plot_2019)
```


---

```{r}
drops <- c("Year","Country", "Continent")
df_master_numeric <- df_master_continent[ , !(names(df_master_continent) %in% drops)]
df_master_numeric <- na.omit(df_master_numeric)
```


```{r}
df_analysis_numeric <- select(df_master_numeric, 'Cost of Living Index', 'Rent Index',
    'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
    'Gross Rental Yield Outside of Centre',
    'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
    'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
    'CO2 Emission Index')

```

```{r}
sum(is.na(df_analysis_numeric))
```

---

# Exploratory Data Analysis


```{r}
# write.csv(df_master_continent,"C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/MasterDF.csv", row.names = FALSE)
```


---

## Correlations

---
### Correlation matrix

First, a correlation matix will be generated with the help of the corrplot package

```{r}

corrplot(cor(df_analysis_numeric), method = "circle", title = "Correlation matrix")
```




The Cost of Living Index is a dependent variable of the Rent Index and the Local Purchasing Power Index. So further correlation analyses are not reasonable. 

But we see that the Pollution Index could be negatively correlated with the Local Purchasing Power Index and with the Cost of Living Index. 

The CO2 Emission Index could be positively correlated with Gross Rerntal Yields and Crime Index.  

Furthermore, the Health Care Index seems to be positively correlated with the Local Purchasing Power Index. 
This will be examined in the following

--- 

### Pollution vs. Local Purchasing Power

The function rcorr() [in Hmisc package] can be used to compute the significance levels (p-value) for pearson or spearman correlations. It returns both the correlation coefficients and the p-value of the correlation for all possible pairs of columns in the data table.

Here, we show the (negative) correlation of two variables Polltion Index and Local Purchasing Power Index:
```{r}
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Local Purchasing Power Index`)))
corN
```


see http://www.sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software

---

### Pollution vs. Cost of Living

Here, we show the (negative) correlation of two variables Polltion Index and Cost of Living Index:
```{r}
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Pollution Index`,`Cost of Living Index`)))
corN
```

---

### CO2 Emission  vs. Gross Rental Yield

Here, we show the (positive) correlation of variable CO2 Emission Index and the two indexes for Gross Rental Yields:
```{r}
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield City Centre`)))
corN
```

```{r}
corN <- rcorr(as.matrix(select(df_analysis_numeric,`CO2 Emission Index`,`Gross Rental Yield Outside of Centre`)))
corN
```


---

### Health Care  vs. Local Purchasing Power

The correlation of the two variables Health Care Index and the Local Purchasing Power:
```{r}
corN <- rcorr(as.matrix(select(df_analysis_numeric,`Health Care Index`,`Local Purchasing Power Index`)))
corN
```

---

# Forecasting

Time series analysis for crime rate in Germany

see https://otexts.com/fpp3/
see https://github.com/robjhyndman/fpp3-package

---

Main forecasting methods:


---

## Data Preparation

---


### Preparation Dataframe

Filter dataframe only for Germany

```{r}
df_Germany <- filter(df_master, Country=="Germany")
```


---


### Data transformation into vectors and time series   

In order to be able to work with the partial data sets later, we split the respective dataframe into individual vectors for Crime Index and Year.


```{r}
crimeGermanyVector <- df_Germany[,9]
crimeGermanyVector

costOfLivingVector <- df_Germany[,3]
costOfLivingVector

healthCareVector <- df_Germany[,11]
healthCareVector 

pollutionVector <- df_Germany[,13]
pollutionVector

```


```{r}
class(crimeGermanyVector)
```

---

Now we convert the vectors into times series.
```{r}
crimeGermanyTS <- ts(crimeGermanyVector, start=2012, end=2019, frequency=1)
costOfLivingGermanyTS <- ts(costOfLivingVector, start=2012, end=2019, frequency=1)
healthCareGermanyTS <- ts(healthCareVector, start=2012, end=2019, frequency=1)
pollutionGermanyTS <- ts(pollutionVector, start=2012, end=2019, frequency=1)
crimeGermanyTS
class(crimeGermanyTS)
```

Converting the dataframe into a times series (dataframe is coerced to a numeric matrix)
```{r}
GermanyTS <- ts(df_Germany, start=2012, end=2019, frequency=1)
GermanyTS
```

---

### Plotting times series

```{r}
par(mfrow=c(2,2))
plot(crimeGermanyTS, col="black", main="Crime Index Germany")
plot(costOfLivingGermanyTS, col="red", main="Cost of Living Index Germany")
plot(healthCareGermanyTS, col="orange", main="Health Care Index Germany")
plot(pollutionGermanyTS, col="purple", main="Pollution Index Germany")

```

```{r, warning=FALSE}
library(GGally)
ggCorAnalysis <- select(df_analysis_numeric, `Health Care Index`,`Pollution Index`,`Crime Index`,`Cost of Living Index`)
GGally::ggpairs(ggCorAnalysis)
```

---

## Modelling

---

### Some simple forecasting methods

---

#### Average method

The forecasted values are equal to the average (or “mean”) of the historical data. 
h is the time horizon for the forecast.
```{r}
meanf(crimeGermanyTS, h=3)
```


---

#### Naïve method (random walk forecasts)

The last value of the historical data is set as predicted value. 
h is the time horizon for the forecast.
```{r}
naive(crimeGermanyTS, h=3)
```

Variation: *Drift method*
Change over time (=drift) is the average change in the historical data.
```{r}
driftCrime <- rwf(crimeGermanyTS, h=3, drift=TRUE)
driftCrime

```


---
#### Plotting the forecasts

```{r}
crimeGermanyPlot <- window(crimeGermanyTS,start=2012,end=2019)
# Plot some forecasts
autoplot(crimeGermanyPlot) +
  autolayer(meanf(crimeGermanyPlot, h=3),
    series="Mean", PI=FALSE) +
  autolayer(naive(crimeGermanyPlot, h=3),
    series="Naïve", PI=FALSE) +
  autolayer(rwf(crimeGermanyTS, h=3, drift=TRUE),
    series="Naïve Drift Method", PI=FALSE) +
  ggtitle("Forecasts for Crime Index") +
  xlab("Year") + ylab("Crime Index") +
  guides(colour=guide_legend(title="Forecast"))
```


---

#### Evaluating Forecast Accuracy

For the three methods Mean, Naïve Method and Drift Method the Accuracy can be deducted from comparison of forecasts 2017-2019 and real data.

```{r}
crime1 <- meanf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime2 <- rwf(window(crimeGermanyTS, start=2012, end=2016), h=3)
crime3 <- rwf(window(crimeGermanyTS, start=2012, end=2016), drift=TRUE, h=3)
autoplot(crimeGermanyPlot) +
  autolayer(crime1, PI=FALSE, series="Mean") +
  autolayer(crime2, PI=FALSE, series="Naïve") +
  autolayer(crime3, PI=FALSE, series="Naïve Drift Method") +
  xlab("Year") + ylab("Crime Index") +
  ggtitle("Crime Index Germany") +
  guides(colour=guide_legend(title="Forecast"))
```


---

### Autocorrelation
We measure the relationship between: 
yt and yt-1
yt and yt-2
yt and yt-3
etc.

---
```{r}
lag.plot(crimeGermanyTS,lags=7,do.lines=FALSE)
```
The autocorrelations are the correlations associated with these scatterplots.

---

The autocorrelations coefficients are displayed by the autocorrelation function ggAcf function
```{r}
ggAcf(crimeGermanyTS)

```

The dashed blue lines (±2/√T where T is the length of the time, in our case ±0,76) indicate whether the correlations are significantly different from zero.
In our case no correlation is significant. 
Time series that show no autocorrelation are called *white noise*. 

---
### Non-seasonal ARIMA models

```{r}

```




```{r}

```




```{r}

```



```{r}

```



```{r}

```



```{r}

```

