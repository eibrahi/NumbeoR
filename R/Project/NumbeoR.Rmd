---
title: "Project assignment NumbeoR"
author: "Elvir Ibrahimovic & Svetislav Bratic"
date: "29 9 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



---

# Project Description


---

# Required libraries

```{r, message=FALSE}
library("tidyverse")

library(DBI)                           # for PostgreSQL
library(RPostgreSQL)                   # for PostgreSQL

library("jsonlite")                    # JSON files
library("rjson")

library(plotly)                        # Visualisierungen
```

---

# Setup of the PostgreSQL database

---

## Establishing connection to PostgreSQL

```{r}
pw ="HdM2019"

# loads the PostgreSQL driver
drv <- dbDriver("PostgreSQL") 

# creates a connection to the postgres database; "con" is used to connect to the database
con <- dbConnect(drv, dbname = "NumbeoR",
                 host = "localhost", port = 5432,
                 user = "postgres", password = pw)

# removes the password
rm(pw)

```

---

## Creation of database
A database with the name "NumbeoR" in PostgreSQL has to be created manually. 

---

## Creation of tables

Six different tables need to be created:

```{sql eval=FALSE, connection=con, include=FALSE}
CREATE TABLE cost_of_living (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Cost of Living Index" numeric,                   -- Cost of Living Index
    "Rent Index" numeric,                             -- Rent Index
    "Cost of Living Plus Rent Index" numeric,   
    "Groceries Index" numeric,                   
    "Restaurant Price Index" numeric,                  
    "Local Purchasing Power Index" numeric                        
);

CREATE TABLE crime (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Crime Index" numeric,              
    "Safety Index" numeric
);

CREATE TABLE health_care (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Health Care Index" numeric,              
    "Health CareExp. Index" numeric                        
);

CREATE TABLE pollution (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Pollution Index" numeric,              
    "Exp Pollution Index" numeric                       
);

CREATE TABLE property_investment (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Price To Income Ratio" numeric,              
    "Gross Rental Yield City Centre" numeric,                        
    "Gross Rental Yield Outside of Centre" numeric,   
    "Price To Rent Ratio City Centre" numeric,                   
    "Price To Rent Ratio Outside Of City Centre" numeric,                  
    "Mortgage As A Percentage Of Income" numeric,                   
    "Affordability Index" numeric                      
);

CREATE TABLE traffic (
    "Year" integer,                                   -- Year
    "Country" text,                                   -- Country
    "Traffic Index" numeric,              
    "Time Index(in minutes)" numeric,                        
    "Time Exp. Index" numeric,   
    "Inefficiency Index" numeric,                   
    "CO2 Emission Index" numeric                        
);


```

---

# Data import

Reading in the JSON files

```{r}
json_data_cost_of_living_2017 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/cost-of-living_2017.json")
json_data_cost_of_living_2018 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/cost-of-living_2018.json")
json_data_cost_of_living_2019 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/cost-of-living_2019.json")

json_data_crime_2017 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/crime_2017.json")
json_data_crime_2018 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/crime_2018.json")
json_data_crime_2019 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/crime_2019.json")

json_data_health_care_2017 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/health-care_2017.json")
json_data_health_care_2018 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/health-care_2018.json")
json_data_health_care_2019 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/health-care_2019.json")

json_data_pollution_2017 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/pollution_2017.json")
json_data_pollution_2018 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/pollution_2018.json")
json_data_pollution_2019 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/pollution_2019.json")

json_data_property_investment_2017 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/property-investment_2017.json")
json_data_property_investment_2018 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/property-investment_2018.json")
json_data_property_investment_2019 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/property-investment_2019.json")

json_data_traffic_2017 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/traffic_2017.json")
json_data_traffic_2018 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/traffic_2018.json")
json_data_traffic_2019 <- fromJSON(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/traffic_2019.json")

```

---

Transform JSON files to dataframes, for each JSON file one dataframe is created

```{r}
df_temp_cost_of_living_2017 <- do.call(rbind.data.frame, json_data_cost_of_living_2017)
df_temp_cost_of_living_2018 <- do.call(rbind.data.frame, json_data_cost_of_living_2018)
df_temp_cost_of_living_2019 <- do.call(rbind.data.frame, json_data_cost_of_living_2019)

df_temp_crime_2017 <- do.call(rbind.data.frame, json_data_crime_2017)
df_temp_crime_2018 <- do.call(rbind.data.frame, json_data_crime_2018)
df_temp_crime_2019 <- do.call(rbind.data.frame, json_data_crime_2019)

df_temp_health_care_2017 <- do.call(rbind.data.frame, json_data_health_care_2017)
df_temp_health_care_2018 <- do.call(rbind.data.frame, json_data_health_care_2018)
df_temp_health_care_2019 <- do.call(rbind.data.frame, json_data_health_care_2019)

df_temp_pollution_2017 <- do.call(rbind.data.frame, json_data_pollution_2017)
df_temp_pollution_2018 <- do.call(rbind.data.frame, json_data_pollution_2018)
df_temp_pollution_2019 <- do.call(rbind.data.frame, json_data_pollution_2019)

df_temp_property_investment_2017 <- do.call(rbind.data.frame, json_data_property_investment_2017)
df_temp_property_investment_2018 <- do.call(rbind.data.frame, json_data_property_investment_2018)
df_temp_property_investment_2019 <- do.call(rbind.data.frame, json_data_property_investment_2019)

df_temp_traffic_2017 <- do.call(rbind.data.frame, json_data_traffic_2017)
df_temp_traffic_2018 <- do.call(rbind.data.frame, json_data_traffic_2018)
df_temp_traffic_2019 <- do.call(rbind.data.frame, json_data_traffic_2019)

```

---

The dataframes are transposed to get the required structure

```{r}
df_cost_of_living_2017 <- as.data.frame(t(df_temp_cost_of_living_2017))
df_cost_of_living_2018 <- as.data.frame(t(df_temp_cost_of_living_2018))
df_cost_of_living_2019 <- as.data.frame(t(df_temp_cost_of_living_2019))

df_crime_2017 <- as.data.frame(t(df_temp_crime_2017))
df_crime_2018 <- as.data.frame(t(df_temp_crime_2018))
df_crime_2019 <- as.data.frame(t(df_temp_crime_2019))

df_health_care_2017 <- as.data.frame(t(df_temp_health_care_2017))
df_health_care_2018 <- as.data.frame(t(df_temp_health_care_2018))
df_health_care_2019 <- as.data.frame(t(df_temp_health_care_2019))

df_pollution_2017 <- as.data.frame(t(df_temp_pollution_2017))
df_pollution_2018 <- as.data.frame(t(df_temp_pollution_2018))
df_pollution_2019 <- as.data.frame(t(df_temp_pollution_2019))

df_property_investment_2017 <- as.data.frame(t(df_temp_property_investment_2017))
df_property_investment_2018 <- as.data.frame(t(df_temp_property_investment_2018))
df_property_investment_2019 <- as.data.frame(t(df_temp_property_investment_2019))

df_traffic_2017 <- as.data.frame(t(df_temp_traffic_2017))
df_traffic_2018 <- as.data.frame(t(df_temp_traffic_2018))
df_traffic_2019 <- as.data.frame(t(df_temp_traffic_2019))

```

---

# Writing data into PostgreSQL

The dataframe are now loaded into PostgreSQL for persistent storage

```{r}
dbWriteTable(con, "cost_of_living", 
             value = df_cost_of_living_2017, append = TRUE, row.names = FALSE)
dbWriteTable(con, "cost_of_living", 
             value = df_cost_of_living_2018, append = TRUE, row.names = FALSE)
dbWriteTable(con, "cost_of_living", 
             value = df_cost_of_living_2019, append = TRUE, row.names = FALSE)

dbWriteTable(con, "crime", 
             value = df_crime_2017, append = TRUE, row.names = FALSE)
dbWriteTable(con, "crime", 
             value = df_crime_2018, append = TRUE, row.names = FALSE)
dbWriteTable(con, "crime", 
             value = df_crime_2019, append = TRUE, row.names = FALSE)

dbWriteTable(con, "health_care", 
             value = df_health_care_2017, append = TRUE, row.names = FALSE)
dbWriteTable(con, "health_care", 
             value = df_health_care_2018, append = TRUE, row.names = FALSE)
dbWriteTable(con, "health_care", 
             value = df_health_care_2019, append = TRUE, row.names = FALSE)

dbWriteTable(con, "pollution", 
             value = df_pollution_2017, append = TRUE, row.names = FALSE)
dbWriteTable(con, "pollution", 
             value = df_pollution_2018, append = TRUE, row.names = FALSE)
dbWriteTable(con, "pollution", 
             value = df_pollution_2019, append = TRUE, row.names = FALSE)

dbWriteTable(con, "property_investment", 
             value = df_property_investment_2017, append = TRUE, row.names = FALSE)
dbWriteTable(con, "property_investment", 
             value = df_property_investment_2018, append = TRUE, row.names = FALSE)
dbWriteTable(con, "property_investment", 
             value = df_property_investment_2019, append = TRUE, row.names = FALSE)

dbWriteTable(con, "traffic", 
             value = df_traffic_2017, append = TRUE, row.names = FALSE)
dbWriteTable(con, "traffic", 
             value = df_traffic_2018, append = TRUE, row.names = FALSE)
dbWriteTable(con, "traffic", 
             value = df_traffic_2019, append = TRUE, row.names = FALSE)
```

---

# Export Data From PostgreSQL

There are different ways for exporting and further preparing data from PostgreSQL
One could export with sQL codes
We use R codes instead

---

## R code

---

Export of the different tables with the help of dbGetQuery function

```{r}
df_cost_of_living_postgres <- dbGetQuery(con, "SELECT * from cost_of_living")
df_crime_postgres <- dbGetQuery(con, "SELECT * from crime")
df_health_care_postgres <- dbGetQuery(con, "SELECT * from health_care")
df_pollution_postgres <- dbGetQuery(con, "SELECT * from pollution")
df_property_investment_postgres <- dbGetQuery(con, "SELECT * from property_investment")
df_traffic_postgres <- dbGetQuery(con, "SELECT * from traffic")
```

---
Joining the data to one master dataframe

```{r}
df_master <- full_join(full_join(full_join(full_join(full_join(df_cost_of_living_postgres, df_crime_postgres, by = c("Country", "Year")),df_health_care_postgres, by = c("Country", "Year")), df_pollution_postgres, by = c("Country", "Year")), df_property_investment_postgres, by = c("Country", "Year")), df_traffic_postgres, by = c("Country", "Year"))


df_master
```

```{r}
df_master <- distinct(df_master)

```

```{r}
df_master
```

---

Filtering the master dataframe for country 'Germany'

```{r}
filter(df_master, Country=="Germany")
```

---

## SQL code

---

# Data Understanding and Preparation

---

## Approach:

* Detailed inspection of data and data structure
* Selection of content to be used afterwards
* Outlier detection with the help of descriptive statistics
* Data cleansing (e.g. outlier, NaNs)
* Final validation and verification of data set

---

## Data inspection

---

A summary of dataframe structure and data types can be illustrated with the glimpse function:
```{r}
glimpse(df_master)
```

---

Furthermore we would like to add the information in which continent the country is.

Therefore we import a table which includes a country continent mapping

```{r}
countryContinent <- read.csv(file="C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/countryContinent.csv",header=TRUE, sep=";")
colnames(countryContinent) <- c("Country", "Continent")
```

---

Checking the data types we see that the data was defined as factors

```{r}
glimpse(countryContinent)
```

Therefore we change the data types to characters 
```{r}
countryContinent[] <- lapply(countryContinent, as.character)
```

```{r}
glimpse(countryContinent)
```

---

Now we can join the continents to the master dataframe with the help of a left_join function:

```{r}
df_master_continent <- left_join(df_master,countryContinent, by="Country")
```

Checking the number of NA values within the column 'Continent' shows that there are no ones
```{r}
sum(is.na(df_master_continent["Continent"]))

```

```{r}
df_master_continent[rowSums(is.na(df_master_continent["Continent"])) > 0,]
```

```{r}
glimpse(df_master_continent)
```

---

## Data selection

---

Selection of variables which are to be used in later analyses

```{r}
df_analysis <- select(df_master_continent, Year, Country, 'Cost of Living Index', 'Rent Index',
    'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
    'Gross Rental Yield Outside of Centre',
    'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
    'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
    'CO2 Emission Index', Continent)


```



```{r}
df_analysis

```

```{r}
glimpse(df_analysis)
```

---

## Data Cleansing

---
### Deletion of NA values

Sum of NA values can be ascertained as following:
```{r}
sum(is.na(df_analysis))
```

The observations which contain at least one NA values can be identified with the following command:

```{r}
df_analysis[rowSums(is.na(df_analysis)) > 0,]
```

---

All rows containing NA values can be deleted with the na.omit function:

```{r}
df_analysis_clean <- na.omit(df_analysis)

```

Checking on how many NA values are in the new clean dataframe shows that there are none

```{r}
sum(is.na(df_analysis_clean))
```

The new structure of the dataframe is
```{r}
glimpse(df_analysis_clean)
```


---

```{r}
df_analysis_clean_2019 <- filter(df_analysis_clean, Year == 2019)
```


```{r}
crime_plot_2019 <- ggplot(data=df_analysis_clean_2019, mapping=aes(x=Continent, y=`Crime Index`)) +
                         geom_boxplot()
                     
ggplotly(crime_plot_2019)
```





---


```{r}
crime_health_plot_2019 <- ggplot(df_analysis_clean_2019) +
    geom_point(
        mapping = aes(x = `Pollution Index`, y = `Cost of Living Index`,color= Continent, points=Country)
        )

ggplotly(crime_health_plot_2019)
```


---

```{r}
drops <- c("Year","Country", "Continent")
df_master_numeric <- df_master_continent[ , !(names(df_master_continent) %in% drops)]
df_master_numeric <- na.omit(df_master_numeric)
```


```{r}
df_analysis_numeric <- select(df_master_numeric, 'Cost of Living Index', 'Rent Index',
    'Local Purchasing Power Index', 'Gross Rental Yield City Centre',
    'Gross Rental Yield Outside of Centre',
    'Mortgage As A Percentage Of Income', 'Crime Index', 'Health Care Index',
    'Pollution Index', 'Traffic Index', 'Time Index(in minutes)',
    'CO2 Emission Index')

```

```{r}
sum(is.na(df_analysis_numeric))
```

```{r}
library(corrplot)
corrplot(cor(df_analysis_numeric), method="color", outline="White")
```


```{r}
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(df_analysis_numeric, method="color", col=col(200),  
         type="upper", order="hclust", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.01, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE 
         )
```



```{r}
corrplot(df_analysis_numeric, method="number")
```


# Exploratory Data Analysis


```{r}
# write.csv(df_master_continent,"C:/Users/sveti/Desktop/Diverses/GitProjects/NumbeoR/daten/MasterDF.csv", row.names = FALSE)
```

